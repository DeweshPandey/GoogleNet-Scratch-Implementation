{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZNqiCA0FLGO"
      },
      "outputs": [],
      "source": [
        " import os\n",
        " import cv2\n",
        " import shutil\n",
        " import urllib.request\n",
        " import scipy.stats as stats\n",
        " from collections import OrderedDict\n",
        " from IPython.display import clear_output\n",
        " import numpy as np\n",
        " import matplotlib.pyplot as plt\n",
        " import torch\n",
        " import torch.nn as nn\n",
        " import torch.optim as optim\n",
        " from torch.utils.data import Dataset, DataLoader, random_split\n",
        " from torchvision import transforms, datasets\n",
        " from torchsummary import summary\n",
        " from PIL import Image\n",
        "\n",
        " device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhV89MQ-ifcY",
        "outputId": "25b3dce3-289b-4613-f4b4-32b21b8e10b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the initial Convolutional Block\n",
        "# this will be used in hte stem part of the network i.e. initial\n",
        "class ConvBlock(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride , padding):\n",
        "    super(ConvBlock, self).__init__()\n",
        "\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride , padding)\n",
        "    self.bn = nn.BatchNorm2d(out_channels)\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "  def forward( self, x):\n",
        "    out = self.conv(x)\n",
        "\n",
        "    out = self.bn(out)\n",
        "    out = self.activation(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "Gmq7xFhWKwYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class ConvBlock(nn.Module):\n",
        "\n",
        "#   def __init__(self, in_channels, out_channels, kernel_size, stride , padding):\n",
        "#     super(ConvBlock, self).__init__()\n",
        "\n",
        "#     self.Block = nn.Sequential(\n",
        "#         nn.Conv2d(in_channels, out_channels, kernel_size, stride , padding),\n",
        "#         nn.BatchNorm2d(out_channels),\n",
        "#         nn.ReLU()\n",
        "#     )\n",
        "\n",
        "#   def forward( self, x):\n",
        "#     out = self.Block(x)\n",
        "#     return out"
      ],
      "metadata": {
        "id": "OIUSCxqqMHvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the INCEPTION BLOCK\n",
        "### '#3x3 redunce' and \"#5x5 reduce\"\n",
        "\n",
        "From paper - \"#3 x 3 reduce\" and \"#5x5 reduce\" stands for the number of 1x1 filters in the reduction layer used before the 3x3 and 5x5 convolutions.\n",
        "One can see the number of 1x1 filters in the projection layer after the built-in max pooling in the \"pool proj\" column. \\\n",
        "the purpose of using 1x1 conv filters is to reduce the number of parameters and the number of operations\n",
        "All these reduction/projection layers use rectified linear (ReLU) activation"
      ],
      "metadata": {
        "id": "mZZ4287HM5dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Inceptions(nn.Module):\n",
        "\n",
        "  def __init__( self, in_channels, num1x1, num3x3_reduce, num3x3 , num5x5_reduce, num5x5, pool_proj):\n",
        "    super(Inceptions, self).__init__()\n",
        "\n",
        "    self.block1 = nn.Sequential(\n",
        "        ConvBlock(in_channels, num1x1 , kernel_size=1 , stride =1, padding = 0)\n",
        "    )\n",
        "\n",
        "    self.block2 = nn.Sequential(\n",
        "        ConvBlock(in_channels, num3x3_reduce, kernel_size = 1, stride = 1, padding = 0),\n",
        "        ConvBlock( num3x3_reduce, num3x3, kernel_size =3, stride = 1, padding =1)\n",
        "    )\n",
        "\n",
        "    self.block3 = nn.Sequential(\n",
        "        ConvBlock(in_channels, num5x5_reduce, kernel_size =1, stride = 1 , padding = 0 ),\n",
        "        ConvBlock(num5x5_reduce, num5x5, kernel_size= 5, stride = 1, padding = 2)\n",
        "    )\n",
        "\n",
        "    self.block4 = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1),\n",
        "        ConvBlock( in_channels, pool_proj, kernel_size = 1, stride = 1, padding = 0)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out1 = self.block1(x)\n",
        "    out2 = self.block2(x)\n",
        "    out3 = self.block3(x)\n",
        "    out4 = self.block4(x)\n",
        "\n",
        "    out = torch.cat([out1, out2, out3, out4],1)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "kQ0cPzmGMpTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Auxillary(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels, num_classes):\n",
        "    super(Auxillary, self).__init__()\n",
        "\n",
        "    self.pool = nn.AdaptiveAvgPool2d((4,4))\n",
        "    self.conv = nn.Conv2d(in_channels, 128 , kernel_size =1, stride = 1, padding = 0)\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "    self.fc1 = nn.Linear(2048 , 1024)\n",
        "    self.dropout = nn.Dropout(0.7)\n",
        "    self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(\"x shape is: \", x.shape)\n",
        "    out = self.pool(x)\n",
        "    out = self.conv(out)\n",
        "    out = self.activation(out)\n",
        "    print(\"out shape is: \", out.shape)\n",
        "    out = torch.flatten(out, 1)\n",
        "    out = self.fc1(out)\n",
        "    otu = self.activation(out)\n",
        "    out = self.dropout(out)\n",
        "    out = self.fc2(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "tfae1F9cTkAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogleNet(nn.Module):\n",
        "  def __init__(self, num_classes= 10):\n",
        "\n",
        "    super(GoogleNet, self).__init__()\n",
        "\n",
        "    self.conv1 = ConvBlock( 3, 64, kernel_size= 7 , stride = 2, padding = 3)\n",
        "    self.pool1 = nn.MaxPool2d( 3, stride = 2, padding = 0, ceil_mode = True)\n",
        "    self.conv2 = ConvBlock(64, 64, kernel_size = 1, stride = 1, padding=0 )\n",
        "    self.conv3 = ConvBlock(64, 192, kernel_size = 3, stride = 1, padding = 1)\n",
        "    self.pool3 = nn.MaxPool2d(3, stride = 2, padding = 0, ceil_mode=True)\n",
        "\n",
        "    self.inception3A = Inceptions( in_channels = 192, num1x1 = 64, num3x3_reduce =96, num3x3= 128, num5x5_reduce = 16 ,num5x5 = 32 , pool_proj = 32)\n",
        "    self.inception3B = Inceptions( in_channels = 256, num1x1 = 128, num3x3_reduce =128, num3x3= 192, num5x5_reduce = 32 ,num5x5 = 96 , pool_proj = 64)\n",
        "\n",
        "    self.pool4 = nn.MaxPool2d(3, stride= 2, padding = 0 , ceil_mode = True)\n",
        "\n",
        "    self.inception4A = Inceptions( in_channels = 480, num1x1 = 192, num3x3_reduce =96, num3x3= 208, num5x5_reduce = 16 ,num5x5 = 48 , pool_proj = 64)\n",
        "    self.inception4B = Inceptions( in_channels = 512, num1x1 = 160, num3x3_reduce =112, num3x3= 224, num5x5_reduce = 24 ,num5x5 = 64 , pool_proj = 64)\n",
        "    self.inception4C = Inceptions( in_channels = 512, num1x1 = 128, num3x3_reduce =128, num3x3= 256, num5x5_reduce = 24 ,num5x5 = 64 , pool_proj = 64)\n",
        "    self.inception4D = Inceptions( in_channels = 512, num1x1 = 112, num3x3_reduce =144, num3x3= 288, num5x5_reduce = 32 ,num5x5 = 64 , pool_proj = 64)\n",
        "    self.inception4E = Inceptions( in_channels = 528, num1x1 = 256, num3x3_reduce =160, num3x3= 320, num5x5_reduce = 32 ,num5x5 = 128 , pool_proj = 128)\n",
        "\n",
        "    self.pool5 = nn.MaxPool2d(3, stride = 2, padding = 0, ceil_mode = True)\n",
        "\n",
        "    self.inception5A = Inceptions( in_channels = 832, num1x1 = 256, num3x3_reduce =160, num3x3= 320, num5x5_reduce = 32 ,num5x5 = 128 , pool_proj = 128)\n",
        "    self.inception5B = Inceptions( in_channels = 832, num1x1 = 384, num3x3_reduce =192, num3x3= 384, num5x5_reduce = 48 ,num5x5 = 128 , pool_proj = 128)\n",
        "\n",
        "    self.pool6 = nn.AdaptiveAvgPool2d( (1,1))\n",
        "\n",
        "    self.dropout = nn.Dropout(0.4)\n",
        "    self.fc = nn.Linear( 1024, num_classes)\n",
        "\n",
        "    self.aux4A = Auxillary(512, num_classes)\n",
        "    self.aux4D = Auxillary(528, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.pool1(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.conv3(out)\n",
        "    out = self.pool3(out)\n",
        "\n",
        "    out = self.inception3A(out)\n",
        "    out = self.inception3B(out)\n",
        "    out = self.pool4(out)\n",
        "\n",
        "    out = self.inception4A(out)\n",
        "    aux1 = self.aux4A(out)\n",
        "\n",
        "    out = self.inception4B(out)\n",
        "    out = self.inception4C(out)\n",
        "\n",
        "    out = self.inception4D(out)\n",
        "    aux2 = self.aux4D(out)\n",
        "\n",
        "    out = self.inception4E(out)\n",
        "    out = self.pool5(out)\n",
        "\n",
        "    out = self.inception5A(out)\n",
        "    out = self.inception5B(out)\n",
        "    out = self.pool6(out)\n",
        "\n",
        "    out = torch.flatten(out, 1)\n",
        "\n",
        "    out = self.dropout(out)\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out, aux1, aux2\n",
        "\n"
      ],
      "metadata": {
        "id": "JtHFeeyQxhla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer ):\n",
        "  EPOCHS = 15\n",
        "  train_samples_num = 45000\n",
        "  val_samples_num = 5000\n",
        "  train_epoch_loss_history, val_epoch_loss_history = [], []\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "\n",
        "    train_running_loss = 0\n",
        "    correct_train = 0\n",
        "\n",
        "    # model.train().cuda()\n",
        "    model.train()\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "      inputs , labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      \"\"\" for every mini batch during the training phase we typically want to explicitly set the gradients to zero before starting to do backpropagation \"\"\"\n",
        "      optimizer.grad()\n",
        "\n",
        "      # start the forward pass\n",
        "      prediction0, aux_pred_1, aux_pred_2 = model(inputs)\n",
        "\n",
        "      # Compute the loss\n",
        "      real_loss = criterion(prediction0, labels)\n",
        "      aux_loss1 = criterion(aux_pred_1, labels)\n",
        "      aux_loss2 = criterion(aux_pred_2, labels)\n",
        "\n",
        "      loss = real_loss + aux_loss1 + aux_loss2\n",
        "\n",
        "      # do the backpropagation and update weights with .step() backward pass\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Update the running corrects\n",
        "      _, predicted = torch.max(prediction0.data, 1)\n",
        "      correct_train += (predicted == labels).float().sum().item()\n",
        "\n",
        "      ''' Compare mathc loss\n",
        "      Multiply each average batch loss with batch length\n",
        "      The batch length is inputs.size(0) which gives the number total images in each batch.\n",
        "      Essentially I am un averaging the previously calculated Loss'''\n",
        "      train_running_loss += loss.data.item()*inputs.size(0)\n",
        "\n",
        "    train_epoch_loss = train_running_loss/train_samples_num\n",
        "    train_epoch_loss_history.append(train_epoch_loss)\n",
        "    train_epoch_acc = correct_train/train_samples_num\n",
        "\n",
        "    val_loss = 0\n",
        "    correct_val = 0\n",
        "\n",
        "    # model.eval().cuda()\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for inputs, labels in val_loader:\n",
        "        inputs, labels  = inputs.to(device), labels.to(device)\n",
        "\n",
        "        prediction0, aux_pred_1, aux_pred_2 = model(inputs)\n",
        "\n",
        "        real_loss = criterion(prediction0, labels)\n",
        "        aux_loss1 = criterion(aux_pred_1, labels)\n",
        "        aux_loss2 = criterion(aux_pred_2, labels)\n",
        "\n",
        "        loss = real_loss + aux_loss1 + aux_loss2\n",
        "\n",
        "        _, predicted = torch.max(prediction0.data, 1)\n",
        "\n",
        "        correct_val += (predicted == labels).float().sum().item()\n",
        "\n",
        "        val_loss += loss.data.item()*inputs.size(0)\n",
        "\n",
        "      val_epoch_loss = val_loss/val_samples_num\n",
        "      val_epoch_loss_history.append(val_epoch_loss)\n",
        "      val_epoch_acc = correct_val/val_samples_num\n",
        "\n",
        "    info= f\"For Epoch {epoch+1}/{EPOCHS}: train-loss = {train_epoch_loss:0.5f} | train-acc = {train_acc:0.5f} | val-loss = {val_epoch_loss:0.5f} | val-acc = {val_epoch_acc:0.5f}\"\n",
        "\n",
        "    print(info)\n",
        "\n",
        "    torch.save( model.state.dict(), \"/content/drive/MyDrive/GoogleNet\" )\n",
        "\n",
        "  torch.save(model.state_dict(),\"/content/drive/MyDrive/GoogleNet\")\n",
        "\n",
        "  return train_epoch_loss_history, val_epoch_loss_history\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cAlC6g5K2Cnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GoogleNet()\n",
        "\n",
        "model.to(device)\n",
        "summary(model, (3, 96, 96))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "866loKhiiYSx",
        "outputId": "6455b029-5ba5-4e24-a90a-76a012cb1574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape is:  torch.Size([2, 512, 6, 6])\n",
            "out shape is:  torch.Size([2, 128, 4, 4])\n",
            "x shape is:  torch.Size([2, 528, 6, 6])\n",
            "out shape is:  torch.Size([2, 128, 4, 4])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 48, 48]           9,472\n",
            "       BatchNorm2d-2           [-1, 64, 48, 48]             128\n",
            "              ReLU-3           [-1, 64, 48, 48]               0\n",
            "         ConvBlock-4           [-1, 64, 48, 48]               0\n",
            "         MaxPool2d-5           [-1, 64, 24, 24]               0\n",
            "            Conv2d-6           [-1, 64, 24, 24]           4,160\n",
            "       BatchNorm2d-7           [-1, 64, 24, 24]             128\n",
            "              ReLU-8           [-1, 64, 24, 24]               0\n",
            "         ConvBlock-9           [-1, 64, 24, 24]               0\n",
            "           Conv2d-10          [-1, 192, 24, 24]         110,784\n",
            "      BatchNorm2d-11          [-1, 192, 24, 24]             384\n",
            "             ReLU-12          [-1, 192, 24, 24]               0\n",
            "        ConvBlock-13          [-1, 192, 24, 24]               0\n",
            "        MaxPool2d-14          [-1, 192, 12, 12]               0\n",
            "           Conv2d-15           [-1, 64, 12, 12]          12,352\n",
            "      BatchNorm2d-16           [-1, 64, 12, 12]             128\n",
            "             ReLU-17           [-1, 64, 12, 12]               0\n",
            "        ConvBlock-18           [-1, 64, 12, 12]               0\n",
            "           Conv2d-19           [-1, 96, 12, 12]          18,528\n",
            "      BatchNorm2d-20           [-1, 96, 12, 12]             192\n",
            "             ReLU-21           [-1, 96, 12, 12]               0\n",
            "        ConvBlock-22           [-1, 96, 12, 12]               0\n",
            "           Conv2d-23          [-1, 128, 12, 12]         110,720\n",
            "      BatchNorm2d-24          [-1, 128, 12, 12]             256\n",
            "             ReLU-25          [-1, 128, 12, 12]               0\n",
            "        ConvBlock-26          [-1, 128, 12, 12]               0\n",
            "           Conv2d-27           [-1, 16, 12, 12]           3,088\n",
            "      BatchNorm2d-28           [-1, 16, 12, 12]              32\n",
            "             ReLU-29           [-1, 16, 12, 12]               0\n",
            "        ConvBlock-30           [-1, 16, 12, 12]               0\n",
            "           Conv2d-31           [-1, 32, 12, 12]          12,832\n",
            "      BatchNorm2d-32           [-1, 32, 12, 12]              64\n",
            "             ReLU-33           [-1, 32, 12, 12]               0\n",
            "        ConvBlock-34           [-1, 32, 12, 12]               0\n",
            "        MaxPool2d-35          [-1, 192, 12, 12]               0\n",
            "           Conv2d-36           [-1, 32, 12, 12]           6,176\n",
            "      BatchNorm2d-37           [-1, 32, 12, 12]              64\n",
            "             ReLU-38           [-1, 32, 12, 12]               0\n",
            "        ConvBlock-39           [-1, 32, 12, 12]               0\n",
            "       Inceptions-40          [-1, 256, 12, 12]               0\n",
            "           Conv2d-41          [-1, 128, 12, 12]          32,896\n",
            "      BatchNorm2d-42          [-1, 128, 12, 12]             256\n",
            "             ReLU-43          [-1, 128, 12, 12]               0\n",
            "        ConvBlock-44          [-1, 128, 12, 12]               0\n",
            "           Conv2d-45          [-1, 128, 12, 12]          32,896\n",
            "      BatchNorm2d-46          [-1, 128, 12, 12]             256\n",
            "             ReLU-47          [-1, 128, 12, 12]               0\n",
            "        ConvBlock-48          [-1, 128, 12, 12]               0\n",
            "           Conv2d-49          [-1, 192, 12, 12]         221,376\n",
            "      BatchNorm2d-50          [-1, 192, 12, 12]             384\n",
            "             ReLU-51          [-1, 192, 12, 12]               0\n",
            "        ConvBlock-52          [-1, 192, 12, 12]               0\n",
            "           Conv2d-53           [-1, 32, 12, 12]           8,224\n",
            "      BatchNorm2d-54           [-1, 32, 12, 12]              64\n",
            "             ReLU-55           [-1, 32, 12, 12]               0\n",
            "        ConvBlock-56           [-1, 32, 12, 12]               0\n",
            "           Conv2d-57           [-1, 96, 12, 12]          76,896\n",
            "      BatchNorm2d-58           [-1, 96, 12, 12]             192\n",
            "             ReLU-59           [-1, 96, 12, 12]               0\n",
            "        ConvBlock-60           [-1, 96, 12, 12]               0\n",
            "        MaxPool2d-61          [-1, 256, 12, 12]               0\n",
            "           Conv2d-62           [-1, 64, 12, 12]          16,448\n",
            "      BatchNorm2d-63           [-1, 64, 12, 12]             128\n",
            "             ReLU-64           [-1, 64, 12, 12]               0\n",
            "        ConvBlock-65           [-1, 64, 12, 12]               0\n",
            "       Inceptions-66          [-1, 480, 12, 12]               0\n",
            "        MaxPool2d-67            [-1, 480, 6, 6]               0\n",
            "           Conv2d-68            [-1, 192, 6, 6]          92,352\n",
            "      BatchNorm2d-69            [-1, 192, 6, 6]             384\n",
            "             ReLU-70            [-1, 192, 6, 6]               0\n",
            "        ConvBlock-71            [-1, 192, 6, 6]               0\n",
            "           Conv2d-72             [-1, 96, 6, 6]          46,176\n",
            "      BatchNorm2d-73             [-1, 96, 6, 6]             192\n",
            "             ReLU-74             [-1, 96, 6, 6]               0\n",
            "        ConvBlock-75             [-1, 96, 6, 6]               0\n",
            "           Conv2d-76            [-1, 208, 6, 6]         179,920\n",
            "      BatchNorm2d-77            [-1, 208, 6, 6]             416\n",
            "             ReLU-78            [-1, 208, 6, 6]               0\n",
            "        ConvBlock-79            [-1, 208, 6, 6]               0\n",
            "           Conv2d-80             [-1, 16, 6, 6]           7,696\n",
            "      BatchNorm2d-81             [-1, 16, 6, 6]              32\n",
            "             ReLU-82             [-1, 16, 6, 6]               0\n",
            "        ConvBlock-83             [-1, 16, 6, 6]               0\n",
            "           Conv2d-84             [-1, 48, 6, 6]          19,248\n",
            "      BatchNorm2d-85             [-1, 48, 6, 6]              96\n",
            "             ReLU-86             [-1, 48, 6, 6]               0\n",
            "        ConvBlock-87             [-1, 48, 6, 6]               0\n",
            "        MaxPool2d-88            [-1, 480, 6, 6]               0\n",
            "           Conv2d-89             [-1, 64, 6, 6]          30,784\n",
            "      BatchNorm2d-90             [-1, 64, 6, 6]             128\n",
            "             ReLU-91             [-1, 64, 6, 6]               0\n",
            "        ConvBlock-92             [-1, 64, 6, 6]               0\n",
            "       Inceptions-93            [-1, 512, 6, 6]               0\n",
            "AdaptiveAvgPool2d-94            [-1, 512, 4, 4]               0\n",
            "           Conv2d-95            [-1, 128, 4, 4]          65,664\n",
            "             ReLU-96            [-1, 128, 4, 4]               0\n",
            "           Linear-97                 [-1, 1024]       2,098,176\n",
            "             ReLU-98                 [-1, 1024]               0\n",
            "          Dropout-99                 [-1, 1024]               0\n",
            "          Linear-100                   [-1, 10]          10,250\n",
            "       Auxillary-101                   [-1, 10]               0\n",
            "          Conv2d-102            [-1, 160, 6, 6]          82,080\n",
            "     BatchNorm2d-103            [-1, 160, 6, 6]             320\n",
            "            ReLU-104            [-1, 160, 6, 6]               0\n",
            "       ConvBlock-105            [-1, 160, 6, 6]               0\n",
            "          Conv2d-106            [-1, 112, 6, 6]          57,456\n",
            "     BatchNorm2d-107            [-1, 112, 6, 6]             224\n",
            "            ReLU-108            [-1, 112, 6, 6]               0\n",
            "       ConvBlock-109            [-1, 112, 6, 6]               0\n",
            "          Conv2d-110            [-1, 224, 6, 6]         226,016\n",
            "     BatchNorm2d-111            [-1, 224, 6, 6]             448\n",
            "            ReLU-112            [-1, 224, 6, 6]               0\n",
            "       ConvBlock-113            [-1, 224, 6, 6]               0\n",
            "          Conv2d-114             [-1, 24, 6, 6]          12,312\n",
            "     BatchNorm2d-115             [-1, 24, 6, 6]              48\n",
            "            ReLU-116             [-1, 24, 6, 6]               0\n",
            "       ConvBlock-117             [-1, 24, 6, 6]               0\n",
            "          Conv2d-118             [-1, 64, 6, 6]          38,464\n",
            "     BatchNorm2d-119             [-1, 64, 6, 6]             128\n",
            "            ReLU-120             [-1, 64, 6, 6]               0\n",
            "       ConvBlock-121             [-1, 64, 6, 6]               0\n",
            "       MaxPool2d-122            [-1, 512, 6, 6]               0\n",
            "          Conv2d-123             [-1, 64, 6, 6]          32,832\n",
            "     BatchNorm2d-124             [-1, 64, 6, 6]             128\n",
            "            ReLU-125             [-1, 64, 6, 6]               0\n",
            "       ConvBlock-126             [-1, 64, 6, 6]               0\n",
            "      Inceptions-127            [-1, 512, 6, 6]               0\n",
            "          Conv2d-128            [-1, 128, 6, 6]          65,664\n",
            "     BatchNorm2d-129            [-1, 128, 6, 6]             256\n",
            "            ReLU-130            [-1, 128, 6, 6]               0\n",
            "       ConvBlock-131            [-1, 128, 6, 6]               0\n",
            "          Conv2d-132            [-1, 128, 6, 6]          65,664\n",
            "     BatchNorm2d-133            [-1, 128, 6, 6]             256\n",
            "            ReLU-134            [-1, 128, 6, 6]               0\n",
            "       ConvBlock-135            [-1, 128, 6, 6]               0\n",
            "          Conv2d-136            [-1, 256, 6, 6]         295,168\n",
            "     BatchNorm2d-137            [-1, 256, 6, 6]             512\n",
            "            ReLU-138            [-1, 256, 6, 6]               0\n",
            "       ConvBlock-139            [-1, 256, 6, 6]               0\n",
            "          Conv2d-140             [-1, 24, 6, 6]          12,312\n",
            "     BatchNorm2d-141             [-1, 24, 6, 6]              48\n",
            "            ReLU-142             [-1, 24, 6, 6]               0\n",
            "       ConvBlock-143             [-1, 24, 6, 6]               0\n",
            "          Conv2d-144             [-1, 64, 6, 6]          38,464\n",
            "     BatchNorm2d-145             [-1, 64, 6, 6]             128\n",
            "            ReLU-146             [-1, 64, 6, 6]               0\n",
            "       ConvBlock-147             [-1, 64, 6, 6]               0\n",
            "       MaxPool2d-148            [-1, 512, 6, 6]               0\n",
            "          Conv2d-149             [-1, 64, 6, 6]          32,832\n",
            "     BatchNorm2d-150             [-1, 64, 6, 6]             128\n",
            "            ReLU-151             [-1, 64, 6, 6]               0\n",
            "       ConvBlock-152             [-1, 64, 6, 6]               0\n",
            "      Inceptions-153            [-1, 512, 6, 6]               0\n",
            "          Conv2d-154            [-1, 112, 6, 6]          57,456\n",
            "     BatchNorm2d-155            [-1, 112, 6, 6]             224\n",
            "            ReLU-156            [-1, 112, 6, 6]               0\n",
            "       ConvBlock-157            [-1, 112, 6, 6]               0\n",
            "          Conv2d-158            [-1, 144, 6, 6]          73,872\n",
            "     BatchNorm2d-159            [-1, 144, 6, 6]             288\n",
            "            ReLU-160            [-1, 144, 6, 6]               0\n",
            "       ConvBlock-161            [-1, 144, 6, 6]               0\n",
            "          Conv2d-162            [-1, 288, 6, 6]         373,536\n",
            "     BatchNorm2d-163            [-1, 288, 6, 6]             576\n",
            "            ReLU-164            [-1, 288, 6, 6]               0\n",
            "       ConvBlock-165            [-1, 288, 6, 6]               0\n",
            "          Conv2d-166             [-1, 32, 6, 6]          16,416\n",
            "     BatchNorm2d-167             [-1, 32, 6, 6]              64\n",
            "            ReLU-168             [-1, 32, 6, 6]               0\n",
            "       ConvBlock-169             [-1, 32, 6, 6]               0\n",
            "          Conv2d-170             [-1, 64, 6, 6]          51,264\n",
            "     BatchNorm2d-171             [-1, 64, 6, 6]             128\n",
            "            ReLU-172             [-1, 64, 6, 6]               0\n",
            "       ConvBlock-173             [-1, 64, 6, 6]               0\n",
            "       MaxPool2d-174            [-1, 512, 6, 6]               0\n",
            "          Conv2d-175             [-1, 64, 6, 6]          32,832\n",
            "     BatchNorm2d-176             [-1, 64, 6, 6]             128\n",
            "            ReLU-177             [-1, 64, 6, 6]               0\n",
            "       ConvBlock-178             [-1, 64, 6, 6]               0\n",
            "      Inceptions-179            [-1, 528, 6, 6]               0\n",
            "AdaptiveAvgPool2d-180            [-1, 528, 4, 4]               0\n",
            "          Conv2d-181            [-1, 128, 4, 4]          67,712\n",
            "            ReLU-182            [-1, 128, 4, 4]               0\n",
            "          Linear-183                 [-1, 1024]       2,098,176\n",
            "            ReLU-184                 [-1, 1024]               0\n",
            "         Dropout-185                 [-1, 1024]               0\n",
            "          Linear-186                   [-1, 10]          10,250\n",
            "       Auxillary-187                   [-1, 10]               0\n",
            "          Conv2d-188            [-1, 256, 6, 6]         135,424\n",
            "     BatchNorm2d-189            [-1, 256, 6, 6]             512\n",
            "            ReLU-190            [-1, 256, 6, 6]               0\n",
            "       ConvBlock-191            [-1, 256, 6, 6]               0\n",
            "          Conv2d-192            [-1, 160, 6, 6]          84,640\n",
            "     BatchNorm2d-193            [-1, 160, 6, 6]             320\n",
            "            ReLU-194            [-1, 160, 6, 6]               0\n",
            "       ConvBlock-195            [-1, 160, 6, 6]               0\n",
            "          Conv2d-196            [-1, 320, 6, 6]         461,120\n",
            "     BatchNorm2d-197            [-1, 320, 6, 6]             640\n",
            "            ReLU-198            [-1, 320, 6, 6]               0\n",
            "       ConvBlock-199            [-1, 320, 6, 6]               0\n",
            "          Conv2d-200             [-1, 32, 6, 6]          16,928\n",
            "     BatchNorm2d-201             [-1, 32, 6, 6]              64\n",
            "            ReLU-202             [-1, 32, 6, 6]               0\n",
            "       ConvBlock-203             [-1, 32, 6, 6]               0\n",
            "          Conv2d-204            [-1, 128, 6, 6]         102,528\n",
            "     BatchNorm2d-205            [-1, 128, 6, 6]             256\n",
            "            ReLU-206            [-1, 128, 6, 6]               0\n",
            "       ConvBlock-207            [-1, 128, 6, 6]               0\n",
            "       MaxPool2d-208            [-1, 528, 6, 6]               0\n",
            "          Conv2d-209            [-1, 128, 6, 6]          67,712\n",
            "     BatchNorm2d-210            [-1, 128, 6, 6]             256\n",
            "            ReLU-211            [-1, 128, 6, 6]               0\n",
            "       ConvBlock-212            [-1, 128, 6, 6]               0\n",
            "      Inceptions-213            [-1, 832, 6, 6]               0\n",
            "       MaxPool2d-214            [-1, 832, 3, 3]               0\n",
            "          Conv2d-215            [-1, 256, 3, 3]         213,248\n",
            "     BatchNorm2d-216            [-1, 256, 3, 3]             512\n",
            "            ReLU-217            [-1, 256, 3, 3]               0\n",
            "       ConvBlock-218            [-1, 256, 3, 3]               0\n",
            "          Conv2d-219            [-1, 160, 3, 3]         133,280\n",
            "     BatchNorm2d-220            [-1, 160, 3, 3]             320\n",
            "            ReLU-221            [-1, 160, 3, 3]               0\n",
            "       ConvBlock-222            [-1, 160, 3, 3]               0\n",
            "          Conv2d-223            [-1, 320, 3, 3]         461,120\n",
            "     BatchNorm2d-224            [-1, 320, 3, 3]             640\n",
            "            ReLU-225            [-1, 320, 3, 3]               0\n",
            "       ConvBlock-226            [-1, 320, 3, 3]               0\n",
            "          Conv2d-227             [-1, 32, 3, 3]          26,656\n",
            "     BatchNorm2d-228             [-1, 32, 3, 3]              64\n",
            "            ReLU-229             [-1, 32, 3, 3]               0\n",
            "       ConvBlock-230             [-1, 32, 3, 3]               0\n",
            "          Conv2d-231            [-1, 128, 3, 3]         102,528\n",
            "     BatchNorm2d-232            [-1, 128, 3, 3]             256\n",
            "            ReLU-233            [-1, 128, 3, 3]               0\n",
            "       ConvBlock-234            [-1, 128, 3, 3]               0\n",
            "       MaxPool2d-235            [-1, 832, 3, 3]               0\n",
            "          Conv2d-236            [-1, 128, 3, 3]         106,624\n",
            "     BatchNorm2d-237            [-1, 128, 3, 3]             256\n",
            "            ReLU-238            [-1, 128, 3, 3]               0\n",
            "       ConvBlock-239            [-1, 128, 3, 3]               0\n",
            "      Inceptions-240            [-1, 832, 3, 3]               0\n",
            "          Conv2d-241            [-1, 384, 3, 3]         319,872\n",
            "     BatchNorm2d-242            [-1, 384, 3, 3]             768\n",
            "            ReLU-243            [-1, 384, 3, 3]               0\n",
            "       ConvBlock-244            [-1, 384, 3, 3]               0\n",
            "          Conv2d-245            [-1, 192, 3, 3]         159,936\n",
            "     BatchNorm2d-246            [-1, 192, 3, 3]             384\n",
            "            ReLU-247            [-1, 192, 3, 3]               0\n",
            "       ConvBlock-248            [-1, 192, 3, 3]               0\n",
            "          Conv2d-249            [-1, 384, 3, 3]         663,936\n",
            "     BatchNorm2d-250            [-1, 384, 3, 3]             768\n",
            "            ReLU-251            [-1, 384, 3, 3]               0\n",
            "       ConvBlock-252            [-1, 384, 3, 3]               0\n",
            "          Conv2d-253             [-1, 48, 3, 3]          39,984\n",
            "     BatchNorm2d-254             [-1, 48, 3, 3]              96\n",
            "            ReLU-255             [-1, 48, 3, 3]               0\n",
            "       ConvBlock-256             [-1, 48, 3, 3]               0\n",
            "          Conv2d-257            [-1, 128, 3, 3]         153,728\n",
            "     BatchNorm2d-258            [-1, 128, 3, 3]             256\n",
            "            ReLU-259            [-1, 128, 3, 3]               0\n",
            "       ConvBlock-260            [-1, 128, 3, 3]               0\n",
            "       MaxPool2d-261            [-1, 832, 3, 3]               0\n",
            "          Conv2d-262            [-1, 128, 3, 3]         106,624\n",
            "     BatchNorm2d-263            [-1, 128, 3, 3]             256\n",
            "            ReLU-264            [-1, 128, 3, 3]               0\n",
            "       ConvBlock-265            [-1, 128, 3, 3]               0\n",
            "      Inceptions-266           [-1, 1024, 3, 3]               0\n",
            "AdaptiveAvgPool2d-267           [-1, 1024, 1, 1]               0\n",
            "         Dropout-268                 [-1, 1024]               0\n",
            "          Linear-269                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 10,348,590\n",
            "Trainable params: 10,348,590\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.11\n",
            "Forward/backward pass size (MB): 22.05\n",
            "Params size (MB): 39.48\n",
            "Estimated Total Size (MB): 61.64\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cifar_dataloader():\n",
        "\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor(), transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "  ])\n",
        "\n",
        "  # iNPUT DATA IN Google Drive\n",
        "\n",
        "  train_dataset = datasets.CIFAR10('/content/drive/MyDrive/input_dataset', train = True, download = True, transform = transform  )\n",
        "  test_dataset = datasets.CIFAR10( '/content/drive/MyDrive/input_dataset', train = False, download = True, transform = transform)\n",
        "\n",
        "  train_dataset , val_dataset = random_split(train_dataset, (45000, 5000))\n",
        "\n",
        "  print( f\"Image shape of random sample image: {train_dataset[0][0].numpy().shape}\", end= '\\r\\n')\n",
        "\n",
        "  print(f\"Training Set: {len(train_dataset)} images\")\n",
        "  print(f\"Validation Set: {len(val_dataset)} images\")\n",
        "  print(f\"Test Set: {len(test_dataset)}\")\n",
        "\n",
        "  BATCH_SIZE = 128\n",
        "\n",
        "  #generate DataLoader\n",
        "\n",
        "  train_loader = DataLoader( train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "  val_loader = DataLoader( val_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "  test_loader = DataLoader( test_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "\n",
        "  return train_loader , val_loader, test_loader\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ejI2m0TekFvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader , val_loader, test_loader = cifar_dataloader()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTkKA3wKt2mR",
        "outputId": "40ffbb93-b944-4b63-e9eb-716f063a9c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Image shape of random sample image: (3, 32, 32)\n",
            "Training Set: 45000 images\n",
            "Validation Set: 5000 images\n",
            "Test Set: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "train_epoch_loss_history, val_epoch_loss_history = train_model(model, train_loader, val_loader, criterion, optimizer)"
      ],
      "metadata": {
        "id": "qbhLBL35uCDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GoogleNet()\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/GoogleNet\"))\n"
      ],
      "metadata": {
        "id": "grSSH0zsuthD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_test_smaples = 10000\n",
        "correct = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    prediction0, aux_pred_1, aux_pred_2 = model(inputs)\n",
        "    _, predicted = torch.max(prediction0.data, 1)\n",
        "    correct += (predicted == labels).float().sum().item()\n",
        "\n",
        "  test_acc = correct/run_test_smaples\n",
        "  print(f\"Test Accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiQS2Y9Juy5j",
        "outputId": "246e45b5-09c5-47d3-a2d6-96332826ee62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleNet(\n",
              "  (conv1): ConvBlock(\n",
              "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (activation): ReLU()\n",
              "  )\n",
              "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (conv2): ConvBlock(\n",
              "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (activation): ReLU()\n",
              "  )\n",
              "  (conv3): ConvBlock(\n",
              "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (activation): ReLU()\n",
              "  )\n",
              "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception3A): Inceptions(\n",
              "    (block1): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block2): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block3): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception3B): Inceptions(\n",
              "    (block1): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block2): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block3): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pool4): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception4A): Inceptions(\n",
              "    (block1): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block2): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block3): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4B): Inceptions(\n",
              "    (block1): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block2): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block3): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4C): Inceptions(\n",
              "    (block1): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block2): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block3): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4D): Inceptions(\n",
              "    (block1): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block2): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block3): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4E): Inceptions(\n",
              "    (block1): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block2): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block3): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pool5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception5A): Inceptions(\n",
              "    (block1): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block2): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block3): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception5B): Inceptions(\n",
              "    (block1): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block2): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block3): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): ConvBlock(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pool6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  (aux4A): Auxillary(\n",
              "    (pool): AdaptiveAvgPool2d(output_size=(4, 4))\n",
              "    (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (activation): ReLU()\n",
              "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (dropout): Dropout(p=0.7, inplace=False)\n",
              "    (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  )\n",
              "  (aux4D): Auxillary(\n",
              "    (pool): AdaptiveAvgPool2d(output_size=(4, 4))\n",
              "    (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (activation): ReLU()\n",
              "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (dropout): Dropout(p=0.7, inplace=False)\n",
              "    (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X65Qg2GIu6f9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}